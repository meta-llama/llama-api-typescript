// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { APIResource } from '../core/resource';
import * as ChatAPI from './chat/chat';
import { APIPromise } from '../core/api-promise';
import { RequestOptions } from '../internal/request-options';

export class Moderations extends APIResource {
  /**
   * Classifies if given messages are potentially harmful across several categories.
   */
  create(body: ModerationCreateParams, options?: RequestOptions): APIPromise<ModerationCreateResponse> {
    return this._client.post('/v1/moderations', { body, ...options });
  }
}

/**
 * A message containing the model's (assistant) response in a chat conversation.
 */
export interface CompletionMessage {
  /**
   * The content of the model's response.
   */
  content: string | ChatAPI.MessageTextContentItem | ChatAPI.MessageReasoningContentItem;

  /**
   * Must be "assistant" to identify this as the model's response
   */
  role: 'assistant';

  /**
   * The reason why we stopped. Options are: - "stop": The model reached a natural
   * stopping point. - "tool_calls": The model finished generating and invoked a tool
   * call. - "length": The model reached the maxinum number of tokens specified in
   * the request.
   */
  stop_reason: 'stop' | 'tool_calls' | 'length';

  /**
   * The tool calls generated by the model, such as function calls.
   */
  tool_calls?: Array<CompletionMessage.ToolCall>;
}

export namespace CompletionMessage {
  export interface ToolCall {
    /**
     * The ID of the tool call.
     */
    id: string;

    /**
     * The function that the model called.
     */
    function: ToolCall.Function;
  }

  export namespace ToolCall {
    /**
     * The function that the model called.
     */
    export interface Function {
      /**
       * The arguments to call the function with, as generated by the model in JSON
       * format. Note that the model does not always generate valid JSON, and may
       * hallucinate parameters not defined by your function schema. Validate the
       * arguments in your code before calling your function.
       */
      arguments: string;

      /**
       * The name of the function to call.
       */
      name: string;
    }
  }
}

/**
 * A message from the user in a chat conversation.
 */
export type Message = UserMessage | SystemMessage | ToolResponseMessage | CompletionMessage;

/**
 * A system message providing instructions or context to the model.
 */
export interface SystemMessage {
  /**
   * The content of the system message.
   */
  content: string | Array<ChatAPI.MessageTextContentItem>;

  /**
   * Must be "system" to identify this as a system message
   */
  role: 'system';
}

/**
 * A message representing the result of a tool invocation.
 */
export interface ToolResponseMessage {
  /**
   * The content of the user message, which can include text and other media.
   */
  content: string | Array<ChatAPI.MessageTextContentItem>;

  /**
   * Must be "tool" to identify this as a tool response
   */
  role: 'tool';

  /**
   * Unique identifier for the tool call this response is for
   */
  tool_call_id: string;
}

/**
 * A message from the user in a chat conversation.
 */
export interface UserMessage {
  /**
   * The content of the user message, which can include text and other media.
   */
  content: string | Array<ChatAPI.MessageTextContentItem | ChatAPI.MessageImageContentItem>;

  /**
   * Must be "user" to identify this as a user message.
   */
  role: 'user';
}

/**
 * Response from a moderation request.
 */
export type ModerationCreateResponse = Array<ModerationCreateResponse.ModerationCreateResponseItem>;

export namespace ModerationCreateResponse {
  export interface ModerationCreateResponseItem {
    flagged: boolean;

    flagged_categories: Array<string>;

    model: string;
  }
}

export interface ModerationCreateParams {
  /**
   * List of messages in the conversation.
   */
  messages: Array<Message>;

  /**
   * Optional identifier of the model to use. Defaults to "Llama-Guard".
   */
  model?: string | null;
}

export declare namespace Moderations {
  export {
    type CompletionMessage as CompletionMessage,
    type Message as Message,
    type SystemMessage as SystemMessage,
    type ToolResponseMessage as ToolResponseMessage,
    type UserMessage as UserMessage,
    type ModerationCreateResponse as ModerationCreateResponse,
    type ModerationCreateParams as ModerationCreateParams,
  };
}
