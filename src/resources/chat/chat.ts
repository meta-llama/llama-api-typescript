// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { APIResource } from '../../core/resource';
import * as CompletionsAPI from './completions';
import {
  CompletionCreateParams,
  CompletionCreateParamsNonStreaming,
  CompletionCreateParamsStreaming,
  Completions,
} from './completions';

export class Chat extends APIResource {
  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);
}

/**
 * A message containing the model's (assistant) response in a chat conversation.
 */
export interface CompletionMessage {
  /**
   * Must be "assistant" to identify this as the model's response
   */
  role: 'assistant';

  /**
   * The content of the model's response.
   */
  content?: string | MessageTextContentItem;

  /**
   * The reason why we stopped. Options are: - "stop": The model reached a natural
   * stopping point. - "tool_calls": The model finished generating and invoked a tool
   * call. - "length": The model reached the maxinum number of tokens specified in
   * the request.
   */
  stop_reason?: 'stop' | 'tool_calls' | 'length';

  /**
   * The tool calls generated by the model, such as function calls.
   */
  tool_calls?: Array<CompletionMessage.ToolCall>;
}

export namespace CompletionMessage {
  export interface ToolCall {
    /**
     * The ID of the tool call.
     */
    id: string;

    /**
     * The function that the model called.
     */
    function: ToolCall.Function;
  }

  export namespace ToolCall {
    /**
     * The function that the model called.
     */
    export interface Function {
      /**
       * The arguments to call the function with, as generated by the model in JSON
       * format. Note that the model does not always generate valid JSON, and may
       * hallucinate parameters not defined by your function schema. Validate the
       * arguments in your code before calling your function.
       */
      arguments: string;

      /**
       * The name of the function to call.
       */
      name: string;
    }
  }
}

/**
 * Response from a chat completion request.
 */
export interface CreateChatCompletionResponse {
  /**
   * The complete response message
   */
  completion_message: CompletionMessage;

  /**
   * The unique identifier of the chat completion request.
   */
  id?: string;

  metrics?: Array<CreateChatCompletionResponse.Metric>;
}

export namespace CreateChatCompletionResponse {
  export interface Metric {
    metric: string;

    value: number;

    unit?: string;
  }
}

/**
 * A chunk of a streamed chat completion response.
 */
export interface CreateChatCompletionResponseStreamChunk {
  /**
   * The event containing the new content
   */
  event: CreateChatCompletionResponseStreamChunk.Event;

  /**
   * The unique identifier of the chat completion request.
   */
  id?: string;
}

export namespace CreateChatCompletionResponseStreamChunk {
  /**
   * The event containing the new content
   */
  export interface Event {
    /**
     * Content generated since last event. This can be one or more tokens, or a tool
     * call.
     */
    delta: Event.TextDelta | Event.ToolCallDelta;

    /**
     * Type of the event
     */
    event_type: 'start' | 'complete' | 'progress' | 'metrics';

    metrics?: Array<Event.Metric>;

    /**
     * The reason why we stopped. Options are: - "stop": The model reached a natural
     * stopping point. - "tool_calls": The model finished generating and invoked a tool
     * call. - "length": The model reached the maxinum number of tokens specified in
     * the request.
     */
    stop_reason?: 'stop' | 'tool_calls' | 'length';
  }

  export namespace Event {
    export interface TextDelta {
      text: string;

      type: 'text';
    }

    export interface ToolCallDelta {
      function: ToolCallDelta.Function;

      type: 'tool_call';

      /**
       * The ID of the tool call.
       */
      id?: string;
    }

    export namespace ToolCallDelta {
      export interface Function {
        /**
         * The arguments to call the function with, as generated by the model in JSON
         * format. Note that the model does not always generate valid JSON, and may
         * hallucinate parameters not defined by your function schema. Validate the
         * arguments in your code before calling your function.
         */
        arguments?: string;

        /**
         * The name of the function to call.
         */
        name?: string;
      }
    }

    export interface Metric {
      metric: string;

      value: number;

      unit?: string;
    }
  }
}

/**
 * A message from the user in a chat conversation.
 */
export type Message = UserMessage | SystemMessage | ToolResponseMessage | CompletionMessage;

/**
 * A image content item
 */
export interface MessageImageContentItem {
  /**
   * Contains either an image URL or a data URL for a base64 encoded image.
   */
  image_url: MessageImageContentItem.ImageURL;

  /**
   * Discriminator type of the content item. Always "image"
   */
  type: 'image_url';
}

export namespace MessageImageContentItem {
  /**
   * Contains either an image URL or a data URL for a base64 encoded image.
   */
  export interface ImageURL {
    /**
     * Either a URL of the image or the base64 encoded image data.
     */
    url: string;
  }
}

/**
 * A text content item
 */
export interface MessageTextContentItem {
  /**
   * Text content
   */
  text: string;

  /**
   * Discriminator type of the content item. Always "text"
   */
  type: 'text';
}

/**
 * A system message providing instructions or context to the model.
 */
export interface SystemMessage {
  /**
   * The content of the system message.
   */
  content: string | Array<MessageTextContentItem>;

  /**
   * Must be "system" to identify this as a system message
   */
  role: 'system';
}

/**
 * A message representing the result of a tool invocation.
 */
export interface ToolResponseMessage {
  /**
   * The content of the user message, which can include text and other media.
   */
  content: string | Array<MessageTextContentItem>;

  /**
   * Must be "tool" to identify this as a tool response
   */
  role: 'tool';

  /**
   * Unique identifier for the tool call this response is for
   */
  tool_call_id: string;
}

/**
 * A message from the user in a chat conversation.
 */
export interface UserMessage {
  /**
   * The content of the user message, which can include text and other media.
   */
  content: string | Array<MessageTextContentItem | MessageImageContentItem>;

  /**
   * Must be "user" to identify this as a user message.
   */
  role: 'user';
}

Chat.Completions = Completions;

export declare namespace Chat {
  export {
    type CompletionMessage as CompletionMessage,
    type CreateChatCompletionResponse as CreateChatCompletionResponse,
    type CreateChatCompletionResponseStreamChunk as CreateChatCompletionResponseStreamChunk,
    type Message as Message,
    type MessageImageContentItem as MessageImageContentItem,
    type MessageTextContentItem as MessageTextContentItem,
    type SystemMessage as SystemMessage,
    type ToolResponseMessage as ToolResponseMessage,
    type UserMessage as UserMessage,
  };

  export {
    Completions as Completions,
    type CompletionCreateParams as CompletionCreateParams,
    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,
    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,
  };
}
